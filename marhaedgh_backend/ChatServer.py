import streamlit as st
import requests
from sqlalchemy.orm import Session
import json

from db.database import get_db
from repository.NotificationRepository import NotificationRepository

VLLM_API_URL = "http://localhost:8000/api/v1/chat-infer"

with st.chat_message("user"):
    st.write("ì•ˆë…•í•˜ì„¸ìš”! Coffit AI ì—ìš”, ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ‘‹")

# ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "context_added" not in st.session_state:
    st.session_state.context_added = False

# ì•Œë¦¼ IDë¡œ ìš”ì•½ë¬¸ ê°€ì ¸ì˜¤ê¸°
if st.query_params.get("alert_id"):
    db: Session = next(get_db())
    notification_repository = NotificationRepository(db)
    notification = notification_repository.get_notification_by_alert_id(st.query_params["alert_id"])
    main_context = {
        "role": "assistant",
        "content": "ë„ˆëŠ” ì •ì±…ê³¼ ì§€ì›ì‚¬ì—…ì— ëŒ€í•´ì„œ ì˜ ì„¤ëª…í•´ì£¼ëŠ” ì •ì±… ì„¤ëª…ê°€ì•¼. ì§€ê¸ˆë¶€í„° ë±‰ëŠ” ë§ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì˜ ë±‰ì–´ì¤˜.\
         ë‹µ í•  ë•Œë§ˆë‹¤ \n ì€ &nbsp; ë¡œ ë°”ê¿”ì„œ ì‚¬ìš©í•´ì¤˜. ë¬¸ë‹¨ê°„ì— ê°œí–‰ì„ í†µí•´ ì„¤ëª… ê°„ì— ê³µê°„ì„ ì¤˜ì„œ ì½ê¸° ì‰½ê²Œ ë§Œë“¤ì–´ì¤˜. \
         ë‹¤ìŒì€ ì‚¬ìš©ìê°€ ì½ê³  ì˜¨ ì •ì±…,\
          ì§€ì›ì‚¬ì—… ë“±ì˜ ìš”ì•½ ë‚´ìš©ì´ì•¼.\n\n\n" + notification.text_summarization
    }
    
    # ìµœì´ˆ ì ‘ì† ì‹œì—ë§Œ ìš”ì•½ë³¸ì„ ì„¸ì…˜ì— ì¶”ê°€ (ì‚¬ìš©ìì—ê²ŒëŠ” ë³´ì´ì§€ ì•ŠìŒ)
    if not st.session_state.context_added:
        st.session_state.messages.insert(0, main_context)
        st.session_state.context_added = True

# ì´ì „ ëŒ€í™” ì¶œë ¥ (main_contextëŠ” ì‚¬ìš©ìì—ê²Œ ë³´ì´ì§€ ì•ŠìŒ)
for message in st.session_state.messages[1:]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        placeholder = st.empty()

        # `st.session_state.messages`ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ payload ìƒì„±
        payload = {
            "messages": st.session_state.messages,
            "stream": True
        }

        # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ì „ì†¡
        response = requests.post(
            VLLM_API_URL,
            data=json.dumps(payload),
            headers={"Content-Type": "application/json"},
            stream=True
        )
        
        # ì„œë²„ì—ì„œ ë°›ì€ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì¶œë ¥
        full_response = ""
        for chunk in response.iter_lines():
            if chunk:
                decoded_chunk = chunk.decode("utf-8")
                full_response += decoded_chunk
                placeholder.markdown(full_response)
        
        # assistantì˜ ì‘ë‹µì„ ì„¸ì…˜ì— ì¶”ê°€
        st.session_state.messages.append({"role": "assistant", "content": full_response})
