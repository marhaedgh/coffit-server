import streamlit as st
import requests
from sqlalchemy.orm import Session
import json

from db.database import get_db
from repository.NotificationRepository import NotificationRepository

API_URL = "http://localhost:9000/api/v1/infer/chat"

def load_basic_prompt():
    path = "/home/guest/marhaedgh/marhaedgh_backend/prompt/chatting_basic.json"
    with open(path, 'r', encoding='utf-8') as file:
        json_data = json.load(file)
        return json_data

def add_to_message_history(role, content):
    message = {"role": role, "content": str(content)}
    st.session_state["messages"].append(
        message
    )

with st.chat_message("assistant"):
    st.write("ì•ˆë…•í•˜ì„¸ìš”! Coffit AI ì—ìš”, ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ‘‹")

notification_summarization = ""
if st.query_params.get("alert_id"):
    db: Session = next(get_db())
    notification_repository = NotificationRepository(db)
    notification = notification_repository.get_notification_by_alert_id(st.query_params["alert_id"])
    notification_summarization = notification.text_summarization

#ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        
    ]

# ì´ì „ ëŒ€í™” ì¶œë ¥ (basic_promptëŠ” ì‚¬ìš©ìì—ê²Œ ë³´ì´ì§€ ì•ŠìŒ)
for message in st.session_state["messages"]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if question := st.chat_input(
    "ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!"
):
    add_to_message_history("user", question)
    with st.chat_message("user"):
        st.write(question)

    with st.chat_message("assistant"):
        
        basic_prompt = load_basic_prompt()
        final_prompt = basic_prompt["content"].format(
            question=question,
            context=notification_summarization,
            messages=st.session_state.messages
        )

        # `st.session_state.messages`ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ payload ìƒì„±
        payload = {
            "question": question,
            "prompt": [{
                "role": "system",
                "content": final_prompt
            }]
        }

        # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ì „ì†¡
        response = requests.post(
            API_URL,
            data=json.dumps(payload),
            headers={"Content-Type": "application/json"},
            stream=True
        )
        
        response_container = st.empty()

        # ì„œë²„ì—ì„œ ë°›ì€ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì¶œë ¥
        full_response = ""
        for chunk in response.iter_content(chunk_size=30):
            if chunk:
                decoded_chunk = chunk.decode("utf-8")
                full_response += decoded_chunk
                response_container.markdown(full_response)
        
        # assistantì˜ ì‘ë‹µì„ ì„¸ì…˜ì— ì¶”ê°€
        st.session_state.messages.append({"role": "assistant", "content": full_response})
